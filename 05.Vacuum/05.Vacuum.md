# ДЗ 05. Настройка autovacuum с учетом особеностей производительности (по лекции 08. MVCC, vacuum и autovacuum)

Создал виртуальную машину **otus-vm-05** в Yandex Cloud согласно [инструкции](../00.Common/01.YC_start.md). Версию PostgreSQL для установки выбираем **15**, как указано в задании. Также небольшое отличие от инструкции по ссылке в характеристиках созданной виртуальной машины: подключил SDD на 10ГБ вместо HDD в качестве основного диска виртуальной машины.

## 1. Синтетическое нагрузочное тестирование с помощью утилиты `pgbench`

**1.1** В качестве тестовой БД будем использовать созданную при установке СУБД базу с именем `postgres`. Планируем использовать утилиту [`pgbench`](https://www.postgresql.org/docs/15/pgbench.html), с помощью которой будем проводить синтетические нагрузочные тесты на установленный кластер.

Создадим тестовые таблицы с предзаполненными данными:

```bash
# SSH-сессия на виртуальной машине
vm:~$ sudo -u postgres pgbench -i postgres
dropping old tables...
NOTICE:  table "pgbench_accounts" does not exist, skipping
NOTICE:  table "pgbench_branches" does not exist, skipping
NOTICE:  table "pgbench_history" does not exist, skipping
NOTICE:  table "pgbench_tellers" does not exist, skipping
creating tables...
generating data (client-side)...
100000 of 100000 tuples (100%) done (elapsed 0.09 s, remaining 0.00 s)
vacuuming...
creating primary keys...
done in 1.15 s (drop tables 0.00 s, create tables 0.01 s, client-side generate 0.12 s, vacuum 0.04 s, primary keys 0.99 s).
```

Здесь с использованием ключа `-i` указали имя БД `postgres`, где создаем тестовые таблицы.

**1.2** Запускаем утилиту для тестирования производительности со следующими параметрами

| Имя параметра | Значение |
|---------------|----------|
|-с8| Эмулируем 8 параллельно работающих клиентов |
|-P 6| Вывод информации о прогрессе каждые 6 секунд|
|-T 60| Выполнять нагрузку на протяжении 60 секунд||
|postgres| Имя БД, на которой необходимо выполнять нагрузку|

Получили следующие результаты:

```bash
# SSH-сессия на виртуальной машине
vm:~$ sudo -u postgres pgbench -c8 -P 6 -T 60 postgres
pgbench (15.6 (Ubuntu 15.6-1.pgdg20.04+1))
starting vacuum...end.
progress: 6.0 s, 655.0 tps, lat 12.132 ms stddev 8.643, 0 failed
progress: 12.0 s, 548.7 tps, lat 14.531 ms stddev 12.138, 0 failed
progress: 18.0 s, 585.5 tps, lat 13.648 ms stddev 10.463, 0 failed
progress: 24.0 s, 476.0 tps, lat 16.701 ms stddev 18.953, 0 failed
progress: 30.0 s, 307.2 tps, lat 26.130 ms stddev 27.742, 0 failed
progress: 36.0 s, 447.2 tps, lat 17.853 ms stddev 14.043, 0 failed
progress: 42.0 s, 527.0 tps, lat 15.145 ms stddev 11.685, 0 failed
progress: 48.0 s, 634.5 tps, lat 12.573 ms stddev 9.535, 0 failed
progress: 54.0 s, 501.5 tps, lat 15.832 ms stddev 16.392, 0 failed
progress: 60.0 s, 345.7 tps, lat 23.263 ms stddev 26.127, 0 failed
transaction type: <builtin: TPC-B (sort of)>
scaling factor: 1
query mode: simple
number of clients: 8
number of threads: 1
maximum number of tries: 1
duration: 60 s
number of transactions actually processed: 30177
number of failed transactions: 0 (0.000%)
latency average = 15.873 ms
latency stddev = 15.849 ms
initial connection time = 19.705 ms
tps = 502.957067 (without initial connection time)
```

Т.е. среднее количество обработанных кластером транзакций в секунду составило **~500** транзакций со средней продолжительностью каждой из них **~16ms**.

**1.3** Редактируем файл **/etc/postgresql/15/main/postgresql.conf** и задаем там следующие настройки

|Имя параметра|Исходное значение|Новое значение|Комментарий|
|-|-|-|-|
|**max_connections** (максимальное число подключений к СУБД)|100|40|Учитывая, что мы планируем в нашем тесте эмулировать не более 8 подключений, то данная настройка не должна повлиять на производительность кластера в рамках наших испытаний|
|**shared_buffers** (размер условного "кеша" СУБД в памяти)|128MB|1GB|Как и предлагается в [документации](https://www.postgresql.org/docs/15/runtime-config-resource.html#GUC-SHARED-BUFFERS) выставляем значение в 25% от доступной памяти сервера |
|**effective_cache_size** (значение "оценки доступной памяти", которое будет использоваться для принятия решений о построении планов планировщиком запросов)|4GB|3GB|Насколько я понимаю, логика здесь выставить значение *<память сервера> - <размер shared_buffers>*, чтобы планировщик предполагал, что для выполнения запросов у него есть 3GB памяти и не приходилось уходить в swap при выполнении запросов. Однако не уверен, что в масштабах нашего синтетического теста это даст какой-либо эффект|
|**maintenance_work_mem** (максимальное количество памяти выделяемое для служебных операций типа VACUUM и команд DDL)|64МБ|512МБ|В нашем тесте будет активно использоваться автовакуум, потому, думаю, увеличение данного параметра позволит кластеру более полно использовать доступные ресурсы сервера|
|**checkpoint_completion_target** (целевое время завершения создания контрольной точки относительно времени до начала создания следующей контрольной точки. Позволяет контролировать нагрузку на диск)|0.9|0.9||
|**wal_buffers** (буфер в памяти для хранения журнала WAL)|-1 (что с измененным размером shared_buffers=1GB будет состалвять 1GB/32=32МБ)|16МБ|Сложно сказать почему в нашей ситуации оставить значение по умолчанию не будет верным решением|
|**default_statistics_target** (количество значений в статистике/гистограмме для каждой таблицы)|100|500|Повышение значения по умолчанию в 5 раз, согласно [документации](https://www.postgresql.org/docs/current/runtime-config-query.html#GUC-DEFAULT-STATISTICS-TARGET) может несколько замедлить команду `ANALYZE` но должно позволить хранить в статистике большее количество записей с меньшим шагом, что может позволить планировщику запросов строить более точный план на основе этой информации. Не уверен, что на объемах в 100 000 строк в нашем синтетическом тесте эти изменения как-то проявят себя|
|**random_page_cost** (относительная стоимость операции "непоследовательного" чтения)|4|4||
|**effective_io_concurrency** (допустимое количество одновременных операций ввода/вывода на диск в рамках одной сессии)|1|2||
|**work_mem** (количество памяти допустимое для одной операции до начала использования временных файлов на диске)|4МБ|Примерно 6.5МБ (6553КБ)|В полтора раза увеличили параметр, что, учитывая параллельную работу не более 8 процессов в рамках нашего синтетического теста, может быть полезным|
|**min_wal_size** (минимальный размер WAL файла)|80МБ|4ГБ|Имеет смысл, чтобы заранее зарезервировать место на диске и снизить необходимость часто переключаться на поиск и выделение дополнительного места на диске под нагрузкой|
|**max_wal_size** (максимальный размер WAL файла)|1ГБ|16ГБ|Выглядит, что несколько рискованное изменение учитывая конфигурацию сервера с 10ГБ дискового пространства. Т.е. потенциально может произойти ситуация, когда место на нашем сервере закончится|

> [!NOTE]
> Я выполнял изменения напрямую в файле конфигурации **postgresql.conf**, однако возможно было также вынести только необходимые параметры в отдельный файл и воспользовальзоваться параметром `include_dir = <путь до папки с файлами конфигурации>` (см. https://www.postgresql.org/docs/15/config-setting.html), чтобы не редактировать каджый раз большой файл со всеми настройками.

**1.4** Повторно запускаем утилиту с теми же параметрами, что и на шаге **1.2**

```bash
# SSH-сессия на виртуальной машине
vm:~$ sudo -u postgres pgbench -c8 -P 6 -T 60 postgres
pgbench (15.6 (Ubuntu 15.6-1.pgdg20.04+1))
starting vacuum...end.
progress: 6.0 s, 490.3 tps, lat 16.146 ms stddev 16.918, 0 failed
progress: 12.0 s, 417.2 tps, lat 19.219 ms stddev 18.779, 0 failed
progress: 18.0 s, 646.3 tps, lat 12.360 ms stddev 8.716, 0 failed
progress: 24.0 s, 538.0 tps, lat 14.823 ms stddev 11.551, 0 failed
progress: 30.0 s, 586.5 tps, lat 13.618 ms stddev 10.134, 0 failed
progress: 36.0 s, 500.8 tps, lat 15.807 ms stddev 16.992, 0 failed
progress: 42.0 s, 401.0 tps, lat 20.083 ms stddev 23.862, 0 failed
progress: 48.0 s, 543.2 tps, lat 14.679 ms stddev 11.303, 0 failed
progress: 54.0 s, 424.5 tps, lat 18.797 ms stddev 15.087, 0 failed
progress: 60.0 s, 639.8 tps, lat 12.511 ms stddev 9.266, 0 failed
transaction type: <builtin: TPC-B (sort of)>
scaling factor: 1
query mode: simple
number of clients: 8
number of threads: 1
maximum number of tries: 1
duration: 60 s
number of transactions actually processed: 31134
number of failed transactions: 0 (0.000%)
latency average = 15.386 ms
latency stddev = 14.536 ms
initial connection time = 19.270 ms
tps = 518.844648 (without initial connection time)
```

Выдало значение в **518** транзакций в секунду (словно бы в рамках погрешности, честно говоря, но на 20 транзакций больше). Повторные попытки выполнения без изменения настроек подтвердили, что это действительно была погрешность и средняя пропускная способность не изменилась и составляет 500 транзакций в секунду.
Более того попробовал использовать параметры с сайла [pgconfig.org](https://www.pgconfig.org/#/?max_connections=100&pg_version=15&environment_name=WEB&total_ram=4&cpus=2&drive_type=SSD&arch=x86-64&os_type=linux) с учетом характеристик созданного нами сервера, и так же не получил никаких изменений :confused: