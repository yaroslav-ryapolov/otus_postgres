---
Слайд 3
***
Всем привет!

Тема проекта - сравнение производительности PostgreSQL в различных архитектурных решениях и в первую очередь мне хотелось посмотреть на практике (пусть и несколько искуственной)
насколько шардирование может помочь при работе с нагрузкой на БД.


---
Слайд 4
***
Краткий план защиты представлен на экране, не будем здесь надолго задерживаться, так как более детальная информация есть на следующих слайдах

---
Слайд 5.
***
Целью проекта, как я уже отмечал ранее, было попробовать в первую очередь посмотреть и посравнивать поведение PostgreSQL под нагрузкой в обычном режиме работы и в формате с шардированием.

Всё это планировал делать в режимах нескольких конфигураций виртуальных машин, на которых будет работать PostgreSQL. В частности, попробовал два основных варианта:
когда главным ограничением является недостаток процессорной мощности
главное ограничение - это медленный диск

---
Слайд 6
***
Планы были большие, но на практике успел сделать гораздо меньше, т.к. даже проделанные эксперименты без учета оформления результатов заняли порядка 30 часов чистого времени.

В итоге основные моменты, которые успел сделать - развернуть пару конфигураций PostgreSQL и потестировать их утилитой pgbench в разных условиях.

---
Слайд 7
***
Использовал небольшое количество уже знакомых всем технологий в этом проекте.

По Yandex Cloud
Отдельно отмечу удобный базовый мониторинг из коробки (но не хватает мониторинга по конкретно работе БД - типа блокировок и подобного, это, подозреваю, есть в управляемых сервисах PostgreSQL, либо нужно разворачивать самому)
Однако есть много нюансов с квотами, лимитами и режимами работы предоставляемых ресурсов (в частности скорость работы HDD может бустится на пол часа два раза в сутки), потому для нагрузки не всегда могут быть сопоставимые и репрезентативные данные
Расширение Citus использовал для шардирования - легко завести, но чтобы заставить работать с выигрышем по производительности нужно учитывать определенные особенности
И был впечатлен утилитой pgbouncer - легко, удобно и быстро настраивается и действительно помогает решать задачу пула соединений сразу без большого потребления ресурсов!

---
Слайд 8
***
Успел потестировать лишь пару вариантов конфигураций по большому счету. Это
Единый узел с одним отдельным диском под PostgreSQL (под данные, wal и логи) - цифра 2 на схеме
Кластер citus из 2 узлов-воркеров и одного узла координатора - цифры 3, 4 и 5
Отдельный узел использовал для запуска pgbench, чтобы не отбирать ресурсы у виртуальных машин под нагрузкой. Там же развернул pgbouncer для экспериментов с ним - цифра 1

В этих конфигурациях я делал по несколько сравнений на различных дисках (медленный сетевой HDD и быстрый SSD) и различном количестве vCPU на каждом из узлов.

---
Слайд 9
***
На экране представлена схема БД для утилиты pgbench. Тут импровизированная схема с банкоматами, счетами и департаментами, а так же историей операций. Использовал скрипт TPC-B - нагрузка простыми транзакциями без учета времени соединения.

Есть ещё типы как минимум типы TCP-A и TCP-С, о них информацию можно поискать в интернете и ссылка на презентации представлена так же.

---
TCP-A - имитация с условиями соединения и подобными вещами (простые транзакции на чтение и обновление)
TCP-B - то же, что TCP-A, но без учета затрат на подключение и подобные вещи
TCP-C - расширение TCP-B более сложными транзакциями с добавлением в сценарий тестирования пакетных операций и длительных фоновых вычислений

---
Слайд 10
***
Для Citus пришлось немного подкорректировать БД, таким образом, чтобы все 4 таблицы можно было шардировать по ключу департамента (таблица branches) - для этого была необходимость включить в состав primary key на всех таблицах идентификатор департамента в том числе (это одно из ограничений при шардировании через Citus)

Данные генерировал утилитой pgbench. Всего использовал БД 4 размеров
1 миллион записей
10 миллионов
100 миллионов
и миллиард.

В сумме все наполненные БД с индексами заняли около 190ГБ места на диске. Если грубо считать, то каждый миллион таких данных занимает у нас примерно 170МБ.

---
Слайд 11
***
Также необходимо было подкорректировать скрипт нагрузки для Citus, чтобы в запросах явно передавалось значение идентификатора департамента, чтобы координатор не запускал распределенные транзакции, но отправлял всё сразу на конкретный узел для обработки

---
Слайд 12
***
Краткая сводка о Citus представлена на слайде. Для совсем простого старта там отличная документация и настраивается очень легко. Но стоит помнить про некоторые особенности и ограничения, которые отмечены на слайде (про вхождение ключа распределения в первичный ключ и необходимость передавать его как условие во всех запросах). Для более тонкой настройки отзыв дать не могу - не использовал)

---
Слайд 13
***
Перейдем к результатам тестирования.

Первый эксперимент - сравнить Citus и единичный узел Postgres в условиях, когда узкое место - это процессор. Здесь настроил хранение данных PostgreSQL на всех узлах (для отдельной ноды и для узлов Citus) на использование высокопроизводительного нереплицируемого SSD. Его характеристики приведены на слайде.

Провел две серии экспериментов на машинах с 2 и 4 процессорами (на каждом узле).

Из таблиц с результатами измерений на слайде видим, что при таком типе нагрузки, когда сами запросы очень легкие, и процессор забит скорее количеством запросов и "инфраструктурной" нагрузкой на их обслуживание, а не долгой обработкой каждого из них, кластер Citus значительно проигрывает в скорости обработки запросов единому узлу и всё, по большому счёту, всё равно упирается в скорость обработки входящих запросов на главном узле-координаторе (нагрузка под 100% как и почти как и на единичном узле)
+ добавляются накладные расходы на общение с узлами-воркерами.

Думаю, картина поменяется, если изменить характер нагрузки и добавить среди нагрузочных транзакций запросы требовательные к вычислительным ресурсам процессора, однако наверняка протестировать этот момент я не успел.

---
Слайд 14
***
Эксперимент с медленным сетевым диском.

В данном эксперименте настроил все узлы на использование 2 vCPU и 4GM RAM и на использование сетевых HDD дисков для хранения данных PostgreSQL
Характеристики дисков приведены на слайде

В данном сравнении уже видим, что картина стала более выгодной в пользу Citus с шардированием, т.к. пропускной способности узла-координатора хватает, чтобы передать весь поток запросов на сторону шардов и нагрузка идёт уже не на один диск, но сразу на два, что значительно увеличивает пропускную способность обработки запросов при необходимости чтения с и записи на диск.

---
Слайд 15
***
В третьем эксперименте попробовал изучить зависимость нагрузки от размера БД и сравнивал под различным количеством клиентов пропускную способность для двух БД: размером в один миллион записей и в один миллиард записей. Замеры для других двух БД (на 10 миллионов записей и на 100 миллионов записей), к сожалению, пока провести не успел.

Сначала удивился результатам: tps на БД в 1 миллиард записей начал ощутимо превосходить пропускную способность на БД в 1 миллион записей, что выглядело очень подозрительно.

Затем по загрузке ресурсов стало понятно, что на 1 миллионе записей не полностью используются ресурсы сервера и появилось подозрение, что дело в блокировках.
Запросами к pg_locks во время нагрузки выявил, что среднее количество активных блокировок на маленькой БД составило 900, в то время как на большой БД - всего 300. То есть разница в несколько раз.

После анализа данных и запросов нагрузки осознал, что на БД в 1 миллион записей создается всего 10 записей о департаментах, а во время нагрузки идут обновления департаментов в том числе. Что и являлось причиной такого неожиданного расхождения нагрузки.

Измерений без команды на обновление департаментов для сравнения, к сожалению, провести не успел.

---
Слайд 16
***
В 4 эксперименте попробовал посмотреть есть ли смысл в пулере соединений на постоянном количестве соединений с размером 100 активных соединений. Для этого попробовал сначала найти тот предел значения количества активных сессий в pgbench, на котором tps начинал уменьшаться. Затем для такого количества максимальных подключений к БД настроил pgbouncer в качестве пулера подключений и проверил пропускную способность конфигурации на 96 активных сессиях в pgbench.

В итоге блокером для увеличения tps в данной конфигурации становились ресурсы процессора. Он был загружен на 100%, а диски были далеки от своих лимитов загрузки. Наибольшее количество tps без пулера я получил на 24 подключениях, потому выставил настройку pgbouncer именно на это значение.

И это дало результаты: пропускная способность восстановилась до значений словно активно 24 подключения, но время обработки отдельной транзакции, разумеется, возросло, т.к. некоторое время транзакции ожидали в очереди pgbouncerа.

